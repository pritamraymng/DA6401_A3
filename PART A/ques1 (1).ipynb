{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11745888,"sourceType":"datasetVersion","datasetId":7373566}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import csv\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.font_manager import FontProperties\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\nimport wandb\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T06:01:11.632687Z","iopub.execute_input":"2025-05-19T06:01:11.632923Z","iopub.status.idle":"2025-05-19T06:01:28.885876Z","shell.execute_reply.started":"2025-05-19T06:01:11.632900Z","shell.execute_reply":"2025-05-19T06:01:28.885338Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ==============================\n# DATA LOADING & ANALYSIS\n# ==============================\ndef data_load_tsv(path):\n    \"\"\"\n    Load data from TSV files with source-target pairs\n    \"\"\"\n    df = pd.read_csv(\n        path,\n        sep='\\t',\n        header=None,\n        dtype=str,\n        quoting=csv.QUOTE_NONE\n    )\n    df = df.dropna(subset=[0,1])\n    return df[0].tolist(), df[1].tolist()\n\n# create char set from multiple lists\ndef create_char_set(*datasets):\n    char_set = set()\n    for data in datasets:\n        for word in data:\n            char_set.update(word)\n    return char_set\n\n# ----------\n# Replace these paths with your own .tsv file locations\ntrain_input, train_output = data_load_tsv(\n    \"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv\"\n)\nval_input, val_output = data_load_tsv(\n    \"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv\"\n)\ntest_input, test_output = data_load_tsv(\n    \"/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv\"\n)\n# ----------\n\n# Print sizes\nprint(f\"Number of training samples:   {len(train_input)}\")\nprint(f\"Number of validation samples: {len(val_input)}\")\nprint(f\"Number of test samples:       {len(test_input)}\")\n\n# Build character sets\nsrc_chars = create_char_set(train_input, val_input, test_input)\ntgt_chars = create_char_set(train_output, val_output, test_output)\n\nprint(\"\\nSource Character Set:\")\nprint(f\"Total characters: {len(src_chars)}\")\nprint(sorted(src_chars))\n\nprint(\"\\nTarget Character Set:\")\nprint(f\"Total characters: {len(tgt_chars)}\")\nprint(sorted(tgt_chars))\n\n# Max seq lengths including <sow> and <eow>\nmax_seq_src = max(len(w) for w in train_input + val_input + test_input) + 2\nmax_seq_tgt = max(len(w) for w in train_output + val_output + test_output) + 2\nprint(f\"\\nMax source seq length (with tokens): {max_seq_src}\")\nprint(f\"Max target seq length (with tokens): {max_seq_tgt}\")\n\n# ==============================\n# INDEX MAPPINGS\n# ==============================\nspecial_tokens = {'<pad>': 0, '<sow>': 1, '<eow>': 2}\n\nsrc2idx = {ch: i+3 for i, ch in enumerate(sorted(src_chars))}\nsrc2idx.update(special_tokens)\nprint(\"\\nSource Indices:\")\nprint(src2idx)\n\nidx2src = {i: ch for ch, i in src2idx.items()}\n\ntgt2idx = {ch: i+3 for i, ch in enumerate(sorted(tgt_chars))}\ntgt2idx.update(special_tokens)\nprint(\"\\nTarget Indices:\")\nprint(tgt2idx)\n\nidx2tgt = {i: ch for ch, i in tgt2idx.items()}\n\nSRC_VOCAB = len(src2idx)\nTGT_VOCAB = len(tgt2idx)\n\n# embedding dims (tunable)\nSRC_EMB_DIM = 64\nTGT_EMB_DIM = 64\n\n# ==============================\n# PREPROCESSING\n# ==============================\ndef tsv_preprocessor(data, max_len, vocab):\n    processed = []\n    for w in data:\n        seq = ['<sow>'] + list(w) + ['<eow>']\n        seq += ['<pad>'] * (max_len - len(seq))\n        indices = [vocab.get(c, vocab['<pad>']) for c in seq]\n        processed.append(torch.LongTensor(indices))\n    return torch.stack(processed)\n\ntrain_src = tsv_preprocessor(train_input, max_seq_src, src2idx)\ntrain_tgt = tsv_preprocessor(train_output, max_seq_tgt, tgt2idx)\nval_src   = tsv_preprocessor(val_input,   max_seq_src, src2idx)\nval_tgt   = tsv_preprocessor(val_output,  max_seq_tgt, tgt2idx)\ntest_src  = tsv_preprocessor(test_input,  max_seq_src, src2idx)\ntest_tgt  = tsv_preprocessor(test_output, max_seq_tgt, tgt2idx)\n\n# ==============================\n# DATASET & DATALOADER\n# ==============================\nclass TSVDataset(Dataset):\n    def __init__(self, src, tgt):\n        self.src = src\n        self.tgt = tgt\n    def __len__(self):\n        return len(self.src)\n    def __getitem__(self, idx):\n        return self.src[idx], self.tgt[idx]\n\n# custom collate to pad along seq dim\n\ndef collate_fn(batch):\n    src_batch, tgt_batch = zip(*batch)\n    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=False, padding_value=special_tokens['<pad>'])\n    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=False, padding_value=special_tokens['<pad>'])\n    return src_padded, tgt_padded\n\nBATCH_SIZE = 256\ntrain_loader = DataLoader(\n    TSVDataset(train_src, train_tgt),\n    batch_size=BATCH_SIZE, shuffle=True,\n    collate_fn=collate_fn\n)\nval_loader = DataLoader(\n    TSVDataset(val_src, val_tgt),\n    batch_size=BATCH_SIZE,\n    collate_fn=collate_fn\n)\ntest_loader = DataLoader(\n    TSVDataset(test_src, test_tgt),\n    batch_size=BATCH_SIZE,\n    collate_fn=collate_fn\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T06:22:15.062768Z","iopub.execute_input":"2025-05-19T06:22:15.063182Z","iopub.status.idle":"2025-05-19T06:22:18.071484Z","shell.execute_reply.started":"2025-05-19T06:22:15.063152Z","shell.execute_reply":"2025-05-19T06:22:18.070942Z"}},"outputs":[{"name":"stdout","text":"Number of training samples:   94543\nNumber of validation samples: 9279\nNumber of test samples:       9228\n\nSource Character Set:\nTotal characters: 60\n['ঁ', 'ং', 'ঃ', 'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', 'ষ', 'স', 'হ', '়', 'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ে', 'ৈ', 'ো', 'ৌ', '্', 'ৎ', '২']\n\nTarget Character Set:\nTotal characters: 26\n['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n\nMax source seq length (with tokens): 24\nMax target seq length (with tokens): 24\n\nSource Indices:\n{'ঁ': 3, 'ং': 4, 'ঃ': 5, 'অ': 6, 'আ': 7, 'ই': 8, 'ঈ': 9, 'উ': 10, 'ঊ': 11, 'ঋ': 12, 'এ': 13, 'ঐ': 14, 'ও': 15, 'ঔ': 16, 'ক': 17, 'খ': 18, 'গ': 19, 'ঘ': 20, 'ঙ': 21, 'চ': 22, 'ছ': 23, 'জ': 24, 'ঝ': 25, 'ঞ': 26, 'ট': 27, 'ঠ': 28, 'ড': 29, 'ঢ': 30, 'ণ': 31, 'ত': 32, 'থ': 33, 'দ': 34, 'ধ': 35, 'ন': 36, 'প': 37, 'ফ': 38, 'ব': 39, 'ভ': 40, 'ম': 41, 'য': 42, 'র': 43, 'ল': 44, 'শ': 45, 'ষ': 46, 'স': 47, 'হ': 48, '়': 49, 'া': 50, 'ি': 51, 'ী': 52, 'ু': 53, 'ূ': 54, 'ৃ': 55, 'ে': 56, 'ৈ': 57, 'ো': 58, 'ৌ': 59, '্': 60, 'ৎ': 61, '২': 62, '<pad>': 0, '<sow>': 1, '<eow>': 2}\n\nTarget Indices:\n{'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28, '<pad>': 0, '<sow>': 1, '<eow>': 2}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ENCODER CLASS\n# ==============================\nclass Encoder(nn.Module):\n    def __init__(\n        self,\n        vocab_size: int,\n        emb_dim: int,\n        hid_dim: int,\n        rnn_type: str = 'gru',\n        num_layers: int = 1,\n        dropout: float = 0.0,\n        bidir: bool = False\n    ):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_dim)\n        rnn_cls = nn.LSTM if rnn_type.lower() == 'lstm' else nn.GRU\n        self.rnn = rnn_cls(\n            input_size=emb_dim,\n            hidden_size=hid_dim,\n            num_layers=num_layers,\n            dropout=dropout if num_layers > 1 else 0.0,\n            bidirectional=bidir,\n            batch_first=True\n        )\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        hidden: torch.Tensor = None,\n        cell: torch.Tensor = None\n    ):\n        emb = self.embedding(x)  # (batch, seq_len, emb_dim)\n        if isinstance(self.rnn, nn.LSTM):\n            if hidden is None or cell is None:\n                out, (h, c) = self.rnn(emb)\n            else:\n                out, (h, c) = self.rnn(emb, (hidden, cell))\n            return out, h, c\n        else:\n            if hidden is None:\n                out, h = self.rnn(emb)\n            else:\n                out, h = self.rnn(emb, hidden)\n            return out, h, None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T06:40:35.607076Z","iopub.execute_input":"2025-05-19T06:40:35.607788Z","iopub.status.idle":"2025-05-19T06:40:35.614397Z","shell.execute_reply.started":"2025-05-19T06:40:35.607766Z","shell.execute_reply":"2025-05-19T06:40:35.613651Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# ==============================\n# DECODER CLASS\n# ==============================\nclass Decoder(nn.Module):\n    def __init__(\n        self,\n        vocab_size: int,\n        emb_dim: int,\n        hid_dim: int,\n        rnn_type: str = 'gru',\n        num_layers: int = 1,\n        dropout: float = 0.0,\n        bidir: bool = False,\n        use_attention: bool = False\n    ):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_dim)\n        rnn_cls = nn.LSTM if rnn_type.lower() == 'lstm' else nn.GRU\n        self.rnn = rnn_cls(\n            input_size=emb_dim,\n            hidden_size=hid_dim,\n            num_layers=num_layers,\n            dropout=dropout if num_layers > 1 else 0.0,\n            bidirectional=bidir,\n            batch_first=True\n        )\n        self.out = nn.Linear(hid_dim, vocab_size)\n        self.use_attention = use_attention\n\n    def forward(\n        self,\n        x: torch.Tensor,\n        prev_hidden: torch.Tensor,\n        prev_cell: torch.Tensor = None,\n        encoder_outputs: torch.Tensor = None\n    ):\n        emb = self.embedding(x)  # (batch, 1, emb_dim)\n        if isinstance(self.rnn, nn.LSTM):\n            if prev_hidden is None or prev_cell is None:\n                dec_out, (h, c) = self.rnn(emb)\n            else:\n                dec_out, (h, c) = self.rnn(emb, (prev_hidden, prev_cell))\n        else:\n            if prev_hidden is None:\n                dec_out, h = self.rnn(emb)\n                c = None\n            else:\n                dec_out, h = self.rnn(emb, prev_hidden)\n                c = None\n        logits = self.out(dec_out)\n        return logits, h, c","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T06:40:40.243300Z","iopub.execute_input":"2025-05-19T06:40:40.243531Z","iopub.status.idle":"2025-05-19T06:40:40.250287Z","shell.execute_reply.started":"2025-05-19T06:40:40.243516Z","shell.execute_reply":"2025-05-19T06:40:40.249549Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# ==============================\n# SEQ2SEQ CLASS\n# ==============================\nclass Seq2Seq(nn.Module):\n    def __init__(\n        self,\n        encoder: Encoder,\n        decoder: Decoder,\n        max_tgt_len: int,\n        teacher_force_rate: float = 0.5\n    ):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.max_tgt_len = max_tgt_len\n        self.teacher_force_rate = teacher_force_rate\n\n    def forward(\n        self,\n        src: torch.Tensor,\n        tgt: torch.Tensor = None,\n        teacher_forcing: bool = True,\n        training: bool = True\n    ):\n        # Encode source sequence\n        enc_outputs, h_enc, c_enc = self.encoder(src)\n\n        # Align hidden/cell to decoder's layers\n        rnn = self.decoder.rnn\n        dirs = 2 if rnn.bidirectional else 1\n        exp_layers = rnn.num_layers * dirs\n        L_enc, B, H = h_enc.size()\n        if L_enc != exp_layers:\n            if L_enc > exp_layers:\n                h = h_enc[:exp_layers]\n                c = c_enc[:exp_layers] if c_enc is not None else None\n            else:\n                pad = exp_layers - L_enc\n                h = torch.cat([h_enc, h_enc.new_zeros(pad, B, H)], 0)\n                if c_enc is not None:\n                    c = torch.cat([c_enc, c_enc.new_zeros(pad, B, H)], 0)\n                else:\n                    c = None\n        else:\n            h, c = h_enc, c_enc\n\n        # Prepare initial decoder input (<sow>=1)\n        dec_in = torch.full((B,1), 1, dtype=torch.long, device=src.device)\n        outputs = torch.zeros(self.max_tgt_len, B, self.decoder.out.out_features, device=src.device)\n\n        for t in range(self.max_tgt_len):\n            logits, h, c = self.decoder(dec_in, h, c, enc_outputs)\n            outputs[t] = logits.squeeze(1)\n            if training and teacher_forcing and random.random() < self.teacher_force_rate:\n                dec_in = tgt[:,t].unsqueeze(1)\n            else:\n                dec_in = logits.argmax(dim=2)\n\n        return outputs, enc_outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T06:40:44.420907Z","iopub.execute_input":"2025-05-19T06:40:44.421205Z","iopub.status.idle":"2025-05-19T06:40:44.429199Z","shell.execute_reply.started":"2025-05-19T06:40:44.421184Z","shell.execute_reply":"2025-05-19T06:40:44.428604Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import wandb\nimport numpy as np\nfrom types import SimpleNamespace\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T06:40:48.837644Z","iopub.execute_input":"2025-05-19T06:40:48.837897Z","iopub.status.idle":"2025-05-19T06:40:48.841557Z","shell.execute_reply.started":"2025-05-19T06:40:48.837878Z","shell.execute_reply":"2025-05-19T06:40:48.840904Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"wandb.login(key='1df7a902fa4a610500b8e79e21818419d5facdbb')#","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T06:40:51.576473Z","iopub.execute_input":"2025-05-19T06:40:51.576727Z","iopub.status.idle":"2025-05-19T06:40:51.655860Z","shell.execute_reply.started":"2025-05-19T06:40:51.576707Z","shell.execute_reply":"2025-05-19T06:40:51.655208Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# ================================================\n# SWEEP CONFIGURATION (Bayesian, no attention)\n# ================================================\nsweep_config = {\n    'method': 'bayes',\n    'name' : 'sweep - no attention',\n    'metric': {\n      'goal': 'maximize',\n      'name': 'validation_accuracy'\n    },\n    'parameters':{\n        'input_embedding_size': {'values': [64, 128]},\n        'enc_layers':            {'values': [1, 2, 3]},\n        'dec_layers':            {'values': [1, 2, 3]},\n        'hidden_size':           {'values': [64, 128, 256]},\n        'cell_type':             {'values': ['lstm', 'rnn', 'gru']},\n        'bidirectional':         {'values': [True]},\n        'dropout':               {'values': [0.1, 0.2, 0.3]},\n        'beam_size':             {'values': [1, 3, 5]}\n    }\n}\n\nsweep_id = wandb.sweep(\n    sweep    = sweep_config,\n    entity   = \"ma23m018-indian-institute-of-technology-madras\",\n    project  = \"MA23M018_assignment3\"\n)\n\n# ================================================\n# AGENT ENTRYPOINT\n# ================================================\ndef main():\n    with wandb.init():\n        cfg = wandb.config\n        # give this run a descriptive name:\n        wandb.run.name = (\n            f\"cell-{cfg.cell_type}_hid-{cfg.hidden_size}\"\n            f\"_emb-{cfg.input_embedding_size}\"\n            f\"_enc-{cfg.enc_layers}_dec-{cfg.dec_layers}\"\n            f\"_drop{cfg.dropout}_beam{cfg.beam_size}\"\n        )\n\n        # build encoder & decoder from sweep params\n        encoder = Encoder(\n            vocab_size    = SRC_VOCAB,\n            emb_dim       = cfg.input_embedding_size,\n            hid_dim       = cfg.hidden_size,\n            rnn_type      = cfg.cell_type,\n            num_layers    = cfg.enc_layers,\n            dropout       = cfg.dropout,\n            bidir         = cfg.bidirectional\n        )\n\n        decoder = Decoder(\n            vocab_size    = TGT_VOCAB,\n            emb_dim       = cfg.input_embedding_size,\n            hid_dim       = cfg.hidden_size,\n            rnn_type      = cfg.cell_type,\n            num_layers    = cfg.dec_layers,\n            dropout       = cfg.dropout,\n            bidir         = cfg.bidirectional,\n            use_attention = False\n        )\n\n        model = Seq2Seq(\n            encoder                = encoder,\n            decoder                = decoder,\n            max_tgt_len            = max_len_tgt,\n            teacher_force_rate     = 0.5\n        ).to(device)\n\n        # train & log validation acc\n        train1(model, train_loader, val_loader, epochs=15)\n\n# launch 50 sweep jobs\nwandb.agent(sweep_id, function=main, count=2)\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T06:40:55.866075Z","iopub.execute_input":"2025-05-19T06:40:55.866781Z","iopub.status.idle":"2025-05-19T06:41:24.185986Z","shell.execute_reply.started":"2025-05-19T06:40:55.866760Z","shell.execute_reply":"2025-05-19T06:41:24.185430Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: j2kvd7d6\nSweep URL: https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4tv4yhjg with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_064102-4tv4yhjg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/4tv4yhjg' target=\"_blank\">light-sweep-1</a></strong> to <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/4tv4yhjg' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/4tv4yhjg</a>"},"metadata":{}},{"name":"stderr","text":"Epochs:   0%|          | 0/15 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_35/3525132711.py\", line 73, in main\n    train1(model, train_loader, val_loader, epochs=15)\n  File \"/tmp/ipykernel_35/908659430.py\", line 49, in train1\n    preds, _ = model(src_batch, tgt_batch, teacher_forcing=True, training=True)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/1047456389.py\", line 52, in forward\n    logits, h, c = self.decoder(dec_in, h, c, enc_outputs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3224703562.py\", line 50, in forward\n    logits = self.out(dec_out)\n             ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (24x512 and 256x29)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cell-lstm_hid-256_emb-64_enc-2_dec-3_drop0.3_beam3</strong> at: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/4tv4yhjg' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/4tv4yhjg</a><br> View project at: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_064102-4tv4yhjg/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 4tv4yhjg errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3525132711.py\", line 73, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train1(model, train_loader, val_loader, epochs=15)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/908659430.py\", line 49, in train1\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     preds, _ = model(src_batch, tgt_batch, teacher_forcing=True, training=True)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/1047456389.py\", line 52, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     logits, h, c = self.decoder(dec_in, h, c, enc_outputs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3224703562.py\", line 50, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     logits = self.out(dec_out)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.linear(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: mat1 and mat2 shapes cannot be multiplied (24x512 and 256x29)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c9oldf36 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 64\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_064117-c9oldf36</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/c9oldf36' target=\"_blank\">gentle-sweep-2</a></strong> to <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/sweeps/j2kvd7d6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/c9oldf36' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/c9oldf36</a>"},"metadata":{}},{"name":"stderr","text":"Epochs:   0%|          | 0/15 [00:00<?, ?it/s]\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_35/3525132711.py\", line 73, in main\n    train1(model, train_loader, val_loader, epochs=15)\n  File \"/tmp/ipykernel_35/908659430.py\", line 49, in train1\n    preds, _ = model(src_batch, tgt_batch, teacher_forcing=True, training=True)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/1047456389.py\", line 52, in forward\n    logits, h, c = self.decoder(dec_in, h, c, enc_outputs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_35/3224703562.py\", line 50, in forward\n    logits = self.out(dec_out)\n             ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (24x256 and 128x29)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cell-lstm_hid-128_emb-64_enc-1_dec-1_drop0.3_beam3</strong> at: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/c9oldf36' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3/runs/c9oldf36</a><br> View project at: <a href='https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3' target=\"_blank\">https://wandb.ai/ma23m018-indian-institute-of-technology-madras/MA23M018_assignment3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_064117-c9oldf36/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run c9oldf36 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3525132711.py\", line 73, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train1(model, train_loader, val_loader, epochs=15)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/908659430.py\", line 49, in train1\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     preds, _ = model(src_batch, tgt_batch, teacher_forcing=True, training=True)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/1047456389.py\", line 52, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     logits, h, c = self.decoder(dec_in, h, c, enc_outputs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_35/3224703562.py\", line 50, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     logits = self.out(dec_out)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.linear(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: mat1 and mat2 shapes cannot be multiplied (24x256 and 128x29)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","output_type":"stream"}],"execution_count":35}]}